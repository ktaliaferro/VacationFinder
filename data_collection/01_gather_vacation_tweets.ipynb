{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this worksheet to gather vacation tweets from Twitter and store them in MySQL.  After executing cell 4, make sure to wait 15 minutes before executing the remaining cells so that you don't exceed the Twitter API limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "from mysql_login_info import sql_username, sql_password\n",
    "from twitter_keys import APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter authentication\n",
    "\n",
    "twitter = Twython(APP_KEY, APP_SECRET,\n",
    "                  OAUTH_TOKEN, OAUTH_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import a list of vacation destinations\n",
    "\n",
    "destinations=[]\n",
    "df_destinations=pd.read_csv('vacation_destinations.txt', header=None, names=['Destination'])\n",
    "destinations = df_destinations['Destination'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search Twitter for \"vacation \"X\"\"\n",
    "# see https://dev.twitter.com/rest/reference/get/search/tweets\n",
    "\n",
    "# count=100 is the maximum allowed amount\n",
    "# 180 queries of this type are allowed per 15 minutes\n",
    "\n",
    "queries_per_destination = 8\n",
    "\n",
    "# Search the first 20 destinations\n",
    "destination_results={}\n",
    "for destination in destinations[:20]:\n",
    "    destination_results[destination]=[]\n",
    "    destination_results[destination].append(twitter.search(q='vacation \"'+destination+'\"', lang='en', count=100, result_type='recent'))\n",
    "    for i in range(1,queries_per_destination):\n",
    "        if len(destination_results[destination][i-1]['statuses']) < 100:\n",
    "            break\n",
    "        max_id=min([status['id'] for status in destination_results[destination][i-1]['statuses']])-1\n",
    "        destination_results[destination].append(twitter.search(q='vacation '+destination, lang='en', count=100, result_type='recent', max_id=max_id))\n",
    "\n",
    "print datetime.datetime.today().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search the next 20 destinations.\n",
    "# wait 15 minutes to do this so as not\n",
    "# to exceed Twitter API limit\n",
    "for destination in destinations[20:]:\n",
    "    destination_results[destination]=[]\n",
    "    destination_results[destination].append(twitter.search(q='vacation \"'+destination+'\"', lang='en', count=100, result_type='recent'))\n",
    "    for i in range(1,queries_per_destination):\n",
    "        if len(destination_results[destination][i-1]['statuses']) < 100:\n",
    "            break\n",
    "        max_id=min([status['id'] for status in destination_results[destination][i-1]['statuses']])-1\n",
    "        destination_results[destination].append(twitter.search(q='vacation '+destination, lang='en', count=100, result_type='recent', max_id=max_id))\n",
    "        \n",
    "print datetime.datetime.today().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organize the results in preparation for putting them in a\n",
    "# pandas dataframe.\n",
    "# Use regex to find the first name of each user\n",
    "\n",
    "destinations_col = []\n",
    "names_col = []\n",
    "first_names_col = []\n",
    "locations_col = []\n",
    "texts_col = []\n",
    "screen_names_col = []\n",
    "ids_col = []\n",
    "times_col = []\n",
    "descriptions_col = []\n",
    "statuses_cnt_col = []\n",
    "\n",
    "for destination in destinations:\n",
    "    for result in destination_results[destination]:\n",
    "        for status in result['statuses']:\n",
    "            destinations_col.append(destination)\n",
    "            screen_names_col.append(status['user']['screen_name'])\n",
    "            name = status['user']['name']\n",
    "            names_col.append(name)\n",
    "            match = re.search('^\\w[a-z]*', name)\n",
    "            if match:\n",
    "                first_names_col.append(match.group())\n",
    "            else:\n",
    "                first_names_col.append(None)\n",
    "            locations_col.append(status['user']['location'])\n",
    "            texts_col.append(status['text'])\n",
    "            ids_col.append(status['id']) # or use ['id_str']\n",
    "            times_col.append(status['created_at'])\n",
    "            descriptions_col.append(status['user']['description'])\n",
    "            statuses_cnt_col.append(status['user']['statuses_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put the results in a Pandas dataframe  \n",
    "df_tweets = pd.DataFrame({\n",
    "        'Destination': destinations_col,\n",
    "        'Screen Name': screen_names_col,\n",
    "        'Full Name': names_col,\n",
    "        'First Name': first_names_col,\n",
    "        'Home Location': locations_col, # Relabel this in later cells\n",
    "        'Tweet': texts_col,\n",
    "        'Tweet ID': ids_col,\n",
    "        'Time': times_col,\n",
    "        'Description': descriptions_col,\n",
    "        'Status Count': statuses_cnt_col\n",
    "    })\n",
    "\n",
    "# Change the character encoding to utf-8.  Maybe use ascii instead?\n",
    "for col in df_tweets.columns.values:\n",
    "    if df_tweets[col].dtype=='object':\n",
    "        df_tweets[col]=df_tweets[col].str.encode('utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to my local mySQL server and open the vacation database\n",
    "engine = create_engine('mysql+mysqldb://'+sql_username+':'+sql_password+'@127.0.0.1:3306/vacation', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data on my mySQL server\n",
    "# copy the pandas dataframe data into the 'vacation_tweets' table on MySQL\n",
    "\n",
    "df_tweets.to_sql('vacation_tweets', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import a list of baby names and put it on my MySQL server\n",
    "\n",
    "df_names = pd.read_csv('baby-names2.csv', usecols=['name'])\n",
    "df_names = df_names.drop_duplicates(['name'])\n",
    "print len(df_names.index), 'baby names names imported'\n",
    "\n",
    "# Save the data on my mySQL server\n",
    "df_names.to_sql('baby_names', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out tweets from users with with names not in the baby names list.\n",
    "# This is to filter out tweets from advertisers and travel agencies.\n",
    "\n",
    "has_name = df_tweets[df_tweets['First Name'].isin(df_names.index)].groupby(['Destination']).size()\n",
    "df_tweets_has_name = df_tweets[df_tweets['First Name'].isin(df_names.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the pandas dataframe data into the 'vacation_tweets_w_name' table\n",
    "# in MySQL\n",
    "\n",
    "df_tweets_has_name.to_sql('vacation_tweets_w_name', engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
